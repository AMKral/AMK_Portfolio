# -*- coding: utf-8 -*-
"""Malaria_Detection_Full_Code_no_split.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xpjuvrMTPw9DG9FRLBYpUy8ONrRVdRBV

# **Malaria Detection**

##<b>Problem Definition</b>
**The context:**

Malaria is caused by the transmission of the plasmodium parasite via mosquito bites. The result is infection of the oxygen-carrying red blood cells (RBCs) and associated respiratory complications. Although the infection is lethal < 1% of the time, in 2019 400,000 cases dies out of more than out 229 million cases, 67% of which were children less than 5 years old.
A confounding issue is that patients can be asymptomatic for over a year thus preventing early treatment. A second issue is that the current method of diagnosis is by manual examination of RBC samples. As this is a manual procedure, the time to diagnosis is not rapid, and, depending on the skill of the examiner, many patients can be misdiagnosed and therefore untreated.
AI and machine learning have already demonstrated improved accuracy over manual diagnosis. Preparation of many samples concurrently is not onerous or subjective, the analysis of these samples is. Taking images of the samples is much more rapid than the analysis, and in cases where no local facilities are available to automate the photography, it should still be possible to take and transmit the images to a center for automated analysis

**The objectives:**

To create an improved automated system to accurately and rapidly diagnose malaria infections. The aim is to develop a deep learning model using images of RBC samples that can be provided even by practitioners in the field.

**The key questions:**

Can deep learning models improve the accuracy of diagnosis?<br>
Can 2D colored images be used for this diagnosis?


**The problem formulation:**

1) Are the data of good enough quality to teach a model?
  Is the dataset large enough? Is it balanced? Are the images of high enough quality? <br>
2) What data processing will be required?
  Resizing to uniform dimensions. How small an image size can we use?
  Do we need to sharpen, de-noise, or otherwise manipulate the images? <br>
3) What image content features are important? The stained plasmodium within the cell? The cell size and shape?<br>
4) How many images per patient are required to minimize any false diagnoses?<br>
5) Which accuracy neasures should be utilized?<br>
6) Could less information rich images (i.e. greyscale) be used instead of color images in those cases that image transmission must be done via cell phone?

## <b>Data Description </b>

There are a total of 24,958 train and 2,600 test images (colored) that we have taken from microscopic images. These images are of the following categories:<br>


**Parasitized:** The parasitized cells contain the Plasmodium parasite which causes malaria<br>
**Uninfected:** The uninfected cells are free of the Plasmodium parasites<br>

###<b> Mount the Drive
"""

#from google.colab import drive
#drive.mount('/content/drive')

"""### <b>Loading libraries</b>"""

# data
import numpy as np
import pandas as pd

# graphing
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns

# image
import cv2
#from google.colab.patches import cv2_imshow
from PIL import Image
import urllib.request

# file / path handling
import os
from zipfile import ZipFile
from numpy import save

import warnings
warnings.filterwarnings("ignore")

"""### <b>Let us load the data</b>

**Note:**
- You must download the dataset from the link provided on Olympus and upload the same to your Google Drive. Then unzip the folder.
"""

# path to the zipped data file
path = '/content/drive/MyDrive/ADSP_Course_1/Capstone Project/cell_images.zip'

# extract data from zipped file
with ZipFile(path, 'r') as zip_ref:
  zip_ref.extractall('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/')

"""The extracted folder has folders for train and test data each containing subfolders for parasitized and uninfected cells.

The individual images need to be collated into arrays for either training or testing and then separated into image arrays and diagnosis arrays.

The images will need to be the same size for the machine learning.<br>
As they are of very different sizes, a final size will be selected. Only images greater than the selected size will be resized, keeping the aspect ratio constant. All the images will be centered on the final size template. Any space not filled with the image will be padded with a single color (white). No resolution will be lost. No distortions added. Minimal images will be reduced in size.



Let's do the same for the training data first and then we will use the same code for the test data as well.
"""

import os
# paths to data files
parent_dir = '/content/drive/MyDrive/ADSP_Course_1/Capstone Project'

# training and testing dir
training_dir = os.path.join(parent_dir, 'cell_images/train')
testing_dir = os.path.join(parent_dir, 'cell_images/test')

# dir containing images
training_parasitized_dir = os.path.join(training_dir, 'parasitized')
training_uninfected_dir = os.path.join(training_dir, 'uninfected')

testing_parasitized_dir = os.path.join(testing_dir, 'parasitized')
testing_uninfected_dir = os.path.join(testing_dir, 'uninfected')

categories = ['parasitized', 'uninfected']

# image / label output (empty) lists
X_test = []
y_test = []
X_train = []
y_train = []

def create_labeled_image_array(parent_drive, image_output_list, label_output_list):
    # parent_drive: training or testing folder path
    # output_lists: empty list for the extracted images and labels

    # loop over category folders
    for category in categories:
        image_path = os.path.join(parent_drive, category)

        # assign label
        label = categories.index(category)

        for img in os.listdir(image_path):
            #read the data using PIL (channel order = RGB)
            image = Image.open(os.path.join(image_path, img))

            # append image and label to output_lists
            image_output_list.append(image)
            label_output_list.append(label)

    # convert to np arrays
    #image_output_list = np.array(image_output_list)
    #label_output_list = np.array(label_output_list)

    return image_output_list, label_output_list

# Create the testing set
X_test, y_test = create_labeled_image_array(testing_dir, X_test, y_test)

# Create the training set
X_train, y_train = create_labeled_image_array(training_dir, X_train, y_train)

# Save np arrays as npy files.

from numpy import save
save('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/X_test.npy', X_test)
save('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/X_train.npy', X_train)
save('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/y_test.npy', y_test)
save('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/y_train.npy', y_train)

# If needed, open np array files
X_test=np.load('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/X_test.npy', allow_pickle=True)
X_train=np.load('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/X_train.npy', allow_pickle=True)
y_test=np.load('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/y_test.npy', allow_pickle=True)
y_train=np.load('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/y_train.npy', allow_pickle=True)

"""###<b> Check the shape of train and test images"""

# Check the shapes of images
print(f"The shape of X_train is {X_train.shape}")
print(f"The shape of X_test is {X_test.shape}")

# Check the shape of a single image in each set
print(f"\nThe shape of X_train, image 2 is {X_train[1].shape}")
print(f"The shape of X_test, image 2 is {X_test[1].shape}")

"""###<b> Check the shape of train and test labels"""

# Check the shapes of labels
print(f"The shape of y_train is {y_train.shape}")
print(f"The shape of y_test is {y_test.shape}")
type(y_test)

"""####<b> Observations and insights:

The train and test sets are the correct lengths.
The X_train and X_test shapes only show the first value (counts) as each image has a different dimensions and therefore don't share the same height and width.<br>
The shape of a single image shows its unique height and width and that there are 3  color channels. This is exactly as it should be.

The y-train and y_test shapes contain the single column representing the infection diagnosis. These will need to be changed to integers.

# Create different dataset splits

Combine all data into one np array
"""

all_images = np.concatenate((X_train, X_test))
all_labels = np.concatenate((y_train, y_test))
print(f"The shape of all_images is: {all_images.shape}")
print(f"The shape of all_labels is: {all_labels.shape}")

#save unsplit data
save('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/all_images.npy', all_images)
save('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/all_labels.npy', all_labels)

# If needed, open np array files
all_images=np.load('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/all_images.npy', allow_pickle=True)
#all_labels=np.load('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/all_labels.npy', allow_pickle=True)



"""### <b>Process the images so that they have the same final dimensions and retain the original aspect ratio unique to the particular image

Why the extra steps?

1) Resizing images can result in distortions as the aspect ratios will  change.

2) Upsizing can impact the resolution of the images.

Why is this important?

There are 2 possible things to be learned from the images: staining of the parasites and the shape of the platelets. Cell shape and size can indicate change within the cell. As I am not sure if cell morphology could play a role in improving accuuracy, it will remain in the data set. If shown to be irrelevant, then it will be discarded.

The height, width, and total area of each image will be determined, a final image size selected, and images larger than the final size will be reduced keeping the aspect ratio stable. A template of the final image size will have images  centered on it and any empty space padded with white pixels.<br>
Unfortunately, it looks like we need to do mean image calculations which would required all the cells to be the same size. --> enlarge the small images even though it means losing some info. In that case, use the mean size rather than the mean + 2*sd
"""

# Add image height and width to all_labels

height = []
width = []
for img in all_images:
    h = img.shape[0]
    w = img.shape[1]
    height.append(h)
    width.append(w)

# convert to arrays
height_np = np.array(height)
width_np = np.array(width)

# Add column to the all_labels numpy arrays
all_labels = np.column_stack((all_labels, height_np))
all_labels = np.column_stack((all_labels, width_np))

print(all_labels[10112:10878])

all_labels_df = pd.DataFrame(all_labels)
print(f"The shape of all_labels_df is {all_labels_df.shape}\n")

############ Naming the columns
all_labels_df.columns = ['Malaria Status', 'Height', 'Width']

all_labels_df['Width'] = all_labels_df['Width'].astype('int')
all_labels_df['Height'] = all_labels_df['Height'].astype('int')

########### Calculate image area
all_labels_df['Area'] = all_labels_df.Height * all_labels_df.Width
all_labels_df.info()

all_labels=np.array(all_labels_df)
all_labels[0:5]

save('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/all_labels.npy', all_labels)

all_labels = np.load('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/dimensions_df.npy', allow_pickle=True)

"""The y_datasets have been combined with all the dimensional data. The distributions will be looked at to determine what the smallest reasonable dimension can be used so that the majority of the images are not shrunk.

###<b> Explore image dimensions**
"""

def histogram_boxplot(data, feature, figsize = (12, 7), kde = False, bins = None):

    """
    Boxplot and histogram combined

    data: dataframe
    feature: dataframe column
    figsize: size of figure (default (12, 7))
    kde: whether to the show density curve (default False)
    bins: number of bins for histogram (default None)
    """

    f2, (ax_box2, ax_hist2) = plt.subplots(
        nrows = 2,      # Number of rows of the subplot grid = 2
        sharex = True,  # X-axis will be shared among all subplots
        gridspec_kw = {"height_ratios": (0.25, 0.75)},
        figsize = figsize,
    )  # Creating the 2 subplots
    sns.boxplot(
        data = data, x = feature, ax = ax_box2, showmeans = True, color = "violet"
    )  # Boxplot will be created and a star will indicate the mean value of the column
    sns.histplot(
        data = data, x = feature, kde = kde, ax = ax_hist2, bins = bins, palette = "winter"
    ) if bins else sns.histplot(
        data = data, x = feature, kde = kde, ax = ax_hist2
    )  # For histogram
    ax_hist2.axvline(
        data[feature].mean(), color = "green", linestyle = "--"
    )  # Add mean to the histogram
    ax_hist2.axvline(
        data[feature].median(), color = "black", linestyle = "-"
    )  # Add median to the histogram

histogram_boxplot(dimensions_df,'Area')

histogram_boxplot(dimensions_df,'Height')

histogram_boxplot(dimensions_df,'Width')

dimensions_df.describe()

dimensions_df = pd.DataFrame(dimensions_df)

height_high = dimensions_df[dimensions_df["Height"] > 173].count()
width_high = dimensions_df[dimensions_df["Width"] > 173].count()
high = (height_high + width_high)

print(f"The number of samples with a dimension > mean + 2*std : {high}.\n\nThis is {high/(dimensions_df.count())}")

"""**Observations**

The distribution of *dimensions were normal.The mean ± std for both h and w were 133 ± 20.

If the uniform size were set to 133 ± 2*std --> 173 pixels, only 7% of the samples would need to be downsized.

For mean images, need to change all image sizes. Will use average instead.

###<b> Determine final image dimensions
"""

# make an array where ALL images share their longest dimension size

def image_size_uniform(images, height_max, width_max):
  images_resized = []
  for img in images:
    h, w = img.shape[:2]
    longest = max(h, w)
    scaling_factor = height_max / (max(h, w))

    resized_img = cv2.resize(img, None, fx=scaling_factor, fy = scaling_factor)
    images_resized.append(resized_img)

  return images_resized

type(all_images)
images_resized = image_size_uniform(all_images, 224, 224)

# Pad all images to the same size
def image_pad_equal_size(images_resized,height_max, width_max):
  images_padded = []
  for img in images_resized:
    h, w = img.shape[:2]

    diff_vert = height_max - h
    pad_top = diff_vert // 2
    pad_bottom = diff_vert - pad_top
    diff_hori = width_max-w
    pad_left = diff_hori // 2
    pad_right = diff_hori - pad_left

    img_padded = cv2.copyMakeBorder(img, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT, value=0)
    assert img_padded.shape[:2] == (height_max, width_max)

    images_padded.append(img_padded)

  return images_padded

images_padded = image_pad_equal_size(images_resized , 224, 224)

#save padded data
save('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/images_padded.npy', images_padded)

images_padded = np.load('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/images_padded.npy', allow_pickle=True)

images_padded = np.array(images_padded)
type(images_padded)

all_img_norm = images_padded/255

#save padded data
save('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/all_img_norm.npy', all_img_norm)

#print(X_test_padded_large_shrunk.shape, X_train_padded_large_shrunk.shape)
#print(X_test_padded.shape, X_train_padded.shape)
#dimensions_df = pd.DataFrame(dimensions_df)
print(dimensions_df.head())

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(all_images, all_labels, test_size = 0.2, random_state=42)

"""### <b>Check the minimum and maximum range of pixel values for train and test images"""

# OpenCV BGR

# note: the original image arrays used in order avoid counting the added padding
print(f"The range of pixel values:\nX_train:\t ({np.amin(X_train[3])}, {np.amax(X_train[3])})")
print(f"X_test: \t ({np.amin(X_test[3])}, {np.amax(X_test[3])})")

print(f"\n(min, max, mean) of color channels:")
print(f"X_test (Blue):\t{X_test[3][:, :, 0].min()}, {X_test[3][:, :, 0].max()}, {int(X_test[3][:, :, 0].mean())}")
print(f"X_test (Green):\t{X_test[3][:, :, 1].min()}, {X_test[3][:, :, 1].max()}, {int(X_test[3][:, :, 1].mean())}")
print(f"X_test (Red):\t{X_test[3][:, :, 2].min()}, {X_test[3][:, :, 2].max()}, {int(X_test[3][:, :, 2].mean())}")
print(f"\nX_train (Blue):\t{X_train[3][:, :, 0].min()}, {X_train[3][:, :, 0].max()}, {int(X_train[3][:, :, 0].mean())}")
print(f"X_train (Green):\t{X_train[3][:, :, 1].min()}, {X_train[3][:, :, 1].max()}, {int(X_train[3][:, :, 1].mean())}")
print(f"X_train (Red):\t{X_train[3][:, :, 2].min()}, {X_train[3][:, :, 2].max()}, {int(X_train[3][:, :, 2].mean())}")

"""####<b> Observations and insights:
There should be very good contrast between the components of the cell in both train and testing data sets.

The training set images have slightly lower max intensity in the B and G channels. Otherwise, the 3 channels show similar intensities<br>
In the training set the red channel is higher than the other 2 channels. May be a consequence of the amount of red stained plasmodium found in the RBCs, although why we don't see something similar in the test set is unclear

###<b> Count the number of values in both uninfected and parasitized
"""

y_test_df = pd.DataFrame(y_test)
y_train_df = pd.DataFrame(y_train)

print(f"The breakdown of test sample types:\n{y_test_df[0].value_counts()}")
print(f"\nThe breakdown of train sample types:\n{y_train_df[0].value_counts()}")

"""###<b>Normalize the images"""

#X_test_padded_large_shrunk_norm = (X_test_padded_large_shrunk/255).astype('float32')
#X_train_padded_large_shrunk_norm = (X_train_padded_large_shrunk/255).astype('float32')
X_test_padded_norm = (X_test_padded/255).astype('float32')
#X_train_padded_norm = (X_train_padded/255).astype('float32')

# Save resized image arrays as npy files.

from numpy import save
#save('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/X_test_padded_large_shrunk_norm.npy', X_test_padded_large_shrunk_norm )
#save('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/X_train_padded_large_shrunk_norm.npy', X_train_padded_large_shrunk_norm)
save('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/X_test_padded_norm.npy', X_test_padded_norm)
#save('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/X_train_padded_norm.npy', X_train_padded_norm)

#X_test_padded_large_shrunk_norm=np.load('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/XX_test_padded_large_shrunk_norm.npy', allow_pickle=True)
#X_train_padded_large_shrunk_norm=np.load('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/X_train_padded_large_shrunk_norm.npy', allow_pickle=True)
X_test_padded_norm=np.load('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/X_test_padded_norm.npy', allow_pickle=True)
X_train_padded_norm = np.load('/content/drive/MyDrive/ADSP_Course_1/Capstone Project/X_train_padded_norm.npy', allow_pickle=True)

X_test_padded_norm.shape, X_train_padded_norm.shape

"""####<b> Observations and insights:

###<b> Plot to check if the data is balanced
"""

figure = plt.figure(figsize = (6,2))
sns.countplot(data=y_test_df[0])
plt.show()
figure = plt.figure(figsize = (6,2))
sns.countplot(data=y_train_df[0])
plt.show()

"""####<b> Observations and insights:
The training and testing data sets samples are close to 1:1 uninfected:infected. They are nicely balanced.

### <b>Data Exploration</b>
Let's visualize the images from the train data
"""

figure = plt.figure(figsize=(10, 20))
for i in range(6):
  ax = plt.subplot(1, 6, i + 1)
  ax.axis('off')
  plt.imshow(X_train_padded_norm [i])
plt.show()

figure = plt.figure(figsize=(10, 20))
for i in range(6):
  ax = plt.subplot(1, 6, i + 1)
  ax.axis('off')
  plt.imshow(X_test_padded_norm [i])
plt.show()

"""####<b> Observations and insights: _____

###<b> Visualize the images with subplot(6, 6) and figsize = (12, 12)
"""

fig = plt.figure(figsize = (12, 12))
#fig.set_size_inches(16,16)


for i in range(36):
  ax = plt.subplot(6, 6, i + 1)
  ax.axis('off')
  plt.imshow(X_train_padded_norm [i])
plt.show()

"""####<b>Observations and insights:

###<b> Plotting the mean images for parasitized and uninfected
"""

# Split images by infection status only

parasitized_images = []
uninfected_images = []

for i, j in zip(X_test_padded_norm, y_test):
  if j=='parasitized':
    parasitized_images.append(i)
  else:
    uninfected_images.append(i)

len(uninfected_images)
for i, j in zip(X_train_padded_norm, y_train):
  if j=='parasitized':
    parasitized_images.append(i)
  else:
    uninfected_images.append(i)

type(uninfected_images)
uninfected_avg= np.array(uninfected_images)
parasitized_avg = np.array(parasitized_images)
uninfected_avg.shape

"""<b> Mean image for parasitized"""

parasitized_avg = np.mean(parasitized_images, axis=0)

parasitized_avg=plt.imshow(parasitized_avg)
plt.axis('off')

plt.show()

"""<b> Mean image for uninfected"""

uninfected_avg = np.mean(uninfected_images, axis=0)

uninfected_avg =plt.imshow(uninfected_avg)
plt.axis('off')

plt.show()

"""####<b> Observations and insights:
There is very little structure that can be overlaid to get a better signal separation beyweem the stained parasite and the RBC.

By eye, the infected cell appears redder consist with have little blobs of red-stained parasite in different places within the RBCs.

### <b>Converting RGB to HSV of Images using OpenCV

###<b> Converting the train data
"""

# Since we originally opened our images using OpenCV, the channels are in the order: BGR
X_train_hsv = []

for img in X_train_padded_norm[:100]:
  img = cv2.cvtColor(img[:, :, :3], cv2.COLOR_BGR2HSV)
  X_train_hsv.append(img)

X_train_hsv=np.array(X_train_hsv)

fig = plt.figure(figsize = (12, 12))
#fig.set_size_inches(16,16)

for i in range(12):
  ax = plt.subplot(6, 6, i + 1)
  ax.axis('off')
  img=X_train_hsv[i]
  plt.imshow(img.astype('uint8'))
plt.show();

"""###<b> Converting the test data"""

X_test_hsv = []

for img in X_test_padded_norm[:100]:
  img = cv2.cvtColor(img[:, :, :3], cv2.COLOR_BGR2HSV)
  X_test_hsv.append(img)

X_test_hsv=np.array(X_test_hsv)

fig = plt.figure(figsize = (12, 12))
#fig.set_size_inches(16,16)

for i in range(12):
  ax = plt.subplot(6, 6, i + 1)
  ax.axis('off')
  img=X_test_hsv[i]
  plt.imshow(img.astype('uint8'))
plt.show();

"""####<b>Observations and insights: _____

###<b> Processing Images using Gaussian Blurring

###<b> Gaussian Blurring on train data

###<b> Gaussian Blurring on test data
"""

gbx=[]  ## to hold the blurred images
for i in np.arange(0,100,1):
    b= cv2.GaussianBlur(X_train_padded_norm[i], (5, 5), 0)
    gbx.append(b)
gbx=np.array(gbx)

figure = plt.figure(figsize=(20,60))
for i in range(6):
  ax = plt.subplot(1, 10, i + 1)
  ax.axis('off')
  plt.imshow(X_train_padded_norm[i])
plt.show()

figure = plt.figure(figsize=(20,60))
for i in range(6):
  ax = plt.subplot(1, 10, i + 1)
  ax.axis('off')
  plt.imshow(gbx[i])
plt.show()

print(gbx.shape)

test_gauss=[]  ## to hold the blurred images
for i in np.arange(0,100,1):
    b= cv2.GaussianBlur(X_test_padded_norm[i], (5, 5), 0)
    test_gauss.append(b)
test_gauss=np.array(test_gauss)

figure = plt.figure(figsize=(20,60))
for i in range(6):
  ax = plt.subplot(1, 10, i + 1)
  ax.axis('off')
  plt.imshow(X_test_padded_norm[i])
plt.show()

figure = plt.figure(figsize=(20,60))
for i in range(6):
  ax = plt.subplot(1, 10, i + 1)
  ax.axis('off')
  plt.imshow(test_gauss[i])
plt.show()

"""####**Observations and insights: _____**

**Think About It:** Would blurring help us for this problem statement in any way? What else can we try?

Gaussian blurring would not be useful in this case. It is useful for images taken in low light (not so w/ microscopic images in general), it can eliminate bright pixels, which would also reduce contrast (not helpful), and for reducing noise from blurry images (shouldn't be the case with the raw data, but processing the data may introduce blurring).

In this case, there is little difference between the original images (top row) and the blurred images (bottome row).

## **Model Building**

### **Base Model**

**Note:** The Base Model has been fully built and evaluated with all outputs shown to give an idea about the process of the creation and evaluation of the performance of a CNN architecture. A similar process can be followed in iterating to build better-performing CNN architectures.

###<b> Importing the required libraries for building and training our Model
"""

import tensorflow as tf
import pandas as pd
import numpy as np
from numpy import random
import matplotlib.pyplot as plt
import seaborn as sns
import random

from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.preprocessing import LabelEncoder

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, LeakyReLU
from tensorflow.keras import backend
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import warnings
warnings.filterwarnings('ignore')

"""####<B>One Hot Encoding the train and test labels"""

y_train_df = pd.DataFrame(y_train)
y_test_df = pd.DataFrame(y_test)

#OHE
y_train_ohe = pd.get_dummies(y_train)
y_test_ohe = pd.get_dummies(y_test)

#Label encoding to change the strings to integers.
y_train_num = y_train_df.apply(LabelEncoder().fit_transform)
y_test_num = y_test_df.apply(LabelEncoder().fit_transform)

y_train_ohe.shape, y_train_num.shape, X_train_padded_norm.shape

"""###<b> Building the model"""

backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)
random.seed(42)

model=Sequential()

# Add input layer
model.add(Flatten(input_shape = (224, 224, 3)))

# Add hidden layers
model.add(Dense(64, activation = 'relu'))
model.add(Dense(32, activation = 'relu'))
model.add(Dense(16, activation = 'relu'))

# Output layer
model.add(Dense(2, activation = 'softmax'))

"""###<b> Compiling the model"""

# compile the model
model.compile(optimizer=Adam(learning_rate = 0.001), loss= 'categorical_crossentropy', metrics = ['accuracy'])

model.summary()

"""<b> Using Callbacks"""



"""<b> Fit and train our Model"""

history = model.fit(X_train_padded_norm, y_train_ohe, validation_split = 0.2, batch_size = 128, epochs = 20, verbose = 1)

"""###<b> Evaluating the model on test data"""

y_pred_test=model.predict(X_test_padded_norm)

"""<b> Plotting the confusion matrix"""

# reverse the one hot coding & calculate max probability
y_pred_classes = np.argmax(y_pred_test, axis = 1)
y_pred_max_prob = np.max(y_pred_test, axis = 1)

# Confirming the extra dimension added by the OHE has been removed
print(type(y_pred_classes[0]))
print(type(y_pred_max_prob[0]))
print(type(y_test_num[0]))


# print classification report
print(classification_report(y_test_num, y_pred_classes))

# Confusion matrix
cm=confusion_matrix(y_test_num, y_pred_classes)
y_classes = range(0,2)
plt.figure(figsize=(5,3))
sns.heatmap(cm, annot = True, fmt = '.0f', xticklabels = y_classes, yticklabels=y_classes)
plt.ylabel('Actual')
plt.xlabel('Predicted');

"""<b>Plotting the train and validation curves"""

plt.figure(figsize=(8,8))
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.ylim(0, 1)
plt.legend(['Train', 'Validation'], loc = 'upper left')
plt.show()

"""So now let's try to build another model with few more add on layers and try to check if we can try to improve the model. Therefore try to build a model by adding few layers if required and altering the activation functions.

###<b> Model 1
####<b> Trying to improve the performance of our model by adding new layers
"""

backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)
random.seed(42)

"""###<b> Building the Model"""

model_1=Sequential()

# Add hidden layers
model_1.add(Conv2D(filters=16, kernel_size=(3, 3), activation = 'relu', padding='same', data_format='channels_last',input_shape = (224, 224, 3)))
model_1.add(Conv2D(filters=16, kernel_size=(3, 3), activation = 'relu', padding='same', data_format='channels_last'))
model_1.add(MaxPool2D(pool_size=(2, 2)))
model_1.add(BatchNormalization())
model_1.add(Dense(64, activation = 'relu'))
model_1.add(Flatten())
model_1.add(Dense(32, activation = 'relu'))
model_1.add(Dropout(0.2))
model_1.add(Dense(16, activation = 'relu'))

# Output layer
model_1.add(Dense(2, activation = 'sigmoid'))

"""###<b> Compiling the model"""

# compile the model
model_1.compile(optimizer=Adam(learning_rate = 0.001), loss= 'categorical_crossentropy', metrics = ['accuracy'])

model_1.summary()
print(y_train_ohe.shape)

"""<b> Using Callbacks"""



"""<b>Fit and Train the model"""

history_1 = model_1.fit(X_train_padded_norm, y_train_ohe, validation_split = 0.2, batch_size = 128, epochs = 15, verbose = 1)

"""###<b> Evaluating the model"""

y_pred_test=model_1.predict(X_test_padded_norm)

"""<b> Plotting the confusion matrix"""

# reverse the one hot coding & calculate max probability
y_pred_classes = np.argmax(y_pred_test, axis = 1)
y_pred_max_prob = np.max(y_pred_test, axis = 1)

# Confirming the extra dimension added by the OHE has been removed
print(type(y_pred_classes[0]))
print(type(y_pred_max_prob[0]))
print(type(y_test_num[0]))


# print classification report
print(classification_report(y_test_num, y_pred_classes))

# Confusion matrix
cm=confusion_matrix(y_test_num, y_pred_classes)
y_classes = range(0,2)
plt.figure(figsize=(5,3))
sns.heatmap(cm, annot = True, fmt = '.0f', xticklabels = y_classes, yticklabels=y_classes)
plt.ylabel('Actual')
plt.xlabel('Predicted');

"""<b> Plotting the train and the validation curves"""

plt.figure(figsize=(8,8))
plt.plot(history_1.history['accuracy'])
plt.plot(history_1.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.ylim(0, 1)
plt.legend(['Train', 'Validation'], loc = 'upper left')
plt.show()

"""###<b>Think about it:</b><br>
Now let's build a model with LeakyRelu as the activation function  

*  Can the model performance be improved if we change our activation function to LeakyRelu?
*  Can BatchNormalization improve our model?

Let us try to build a model using BatchNormalization and using LeakyRelu as our activation function.

###<b> Model 2 with Batch Normalization
"""

backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)
random.seed(42)

"""###<b> Building the Model"""

model_2=Sequential()

# Add hidden layers
model_2.add(Conv2D(filters=16, kernel_size=(3, 3), padding='same', data_format='channels_last',input_shape = (224, 224, 3)))
model_2.add(LeakyReLU(alpha=0.1))
model_2.add(Conv2D(filters=16, kernel_size=(3, 3), padding='same', data_format='channels_last'))
model_2.add(LeakyReLU(alpha=0.1))
model_2.add(MaxPool2D(pool_size=(2, 2)))
model_2.add(Flatten())
model_2.add(Dense(64))
model_2.add(LeakyReLU(alpha=0.1))
model_2.add(BatchNormalization())
model_2.add(LeakyReLU(alpha=0.1))
model_2.add(Dense(16))
model_2.add(LeakyReLU(alpha=0.1))
# Output layer
model_2.add(Dense(2, activation = 'sigmoid'))

"""###<b>Compiling the model"""

# compile the model
model_2.compile(optimizer=Adam(learning_rate = 0.001), loss= 'categorical_crossentropy', metrics = ['accuracy'])

model_2.summary()
print(y_train_ohe.shape)

"""<b> Using callbacks"""

callback = EarlyStopping(monitor='loss', patience = 3)

"""<b>Fit and train the model"""

history_2 = model_2.fit(X_train_padded_norm, y_train_ohe, validation_split = 0.2, batch_size = 128, epochs = 20, verbose = 1, callbacks=callback)

"""<b>Plotting the train and validation accuracy"""

plt.figure(figsize=(8,8))
plt.plot(history_2.history['accuracy'])
plt.plot(history_2.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.ylim(0, 1)
plt.legend(['Train', 'Validation'], loc = 'upper left')
plt.show()

"""###<b>Evaluating the model"""

y_pred_test=model_2.predict(X_test_padded_norm)

# reverse the one hot coding & calculate max probability
y_pred_classes = np.argmax(y_pred_test, axis = 1)
y_pred_max_prob = np.max(y_pred_test, axis = 1)

# Confirming the extra dimension added by the OHE has been removed
print(type(y_pred_classes[0]))
print(type(y_pred_max_prob[0]))
print(type(y_test_num[0]))


# print classification report
print(classification_report(y_test_num, y_pred_classes))

# Confusion matrix
cm=confusion_matrix(y_test_num, y_pred_classes)
y_classes = range(0,2)
plt.figure(figsize=(5,3))
sns.heatmap(cm, annot = True, fmt = '.0f', xticklabels = y_classes, yticklabels=y_classes)
plt.ylabel('Actual')
plt.xlabel('Predicted');

"""####<b>Observations and insights: ____

<b> Generate the classification report and confusion matrix

###**Think About It :**<br>

* Can we improve the model with Image Data Augmentation?
* References to image data augmentation can be seen below:
  *   [Image Augmentation for Computer Vision](https://www.mygreatlearning.com/blog/understanding-data-augmentation/)
  *   [How to Configure Image Data Augmentation in Keras?](https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/)

###<b>Model 3 with Data Augmentation
"""

backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)
random.seed(42)

train_datagen = ImageDataGenerator(shear_range=(0.0-0.5))
result_data= train_datagen.flow(X_train_padded_norm[0:5], y_train[0:5], batch_size=128)

"""###**Think About It :**<br>

*  Check if the performance of the model can be improved by changing different parameters in the ImageDataGenerator.<br>

####<B>Visualizing Augmented images
"""

figure = plt.figure(figsize=(20,60))
for i in range(5):
  ax = plt.subplot(1, 10, i + 1)
  ax.axis('off')
  plt.imshow(X_train_padded_norm[i])
  plt.title("Original Image")
plt.show()

figure = plt.figure(figsize=(20,60))

x = result_data.next()
a=x[0]
b=x[1]
for i in range(0, 5):
  ax = plt.subplot(1, 10, i + 1)
  ax.axis('off')
  plt.imshow(a[i])
  plt.title(b[i])
plt.show()



"""####<b>Observations and insights: <br>
Of the different augmentations, there are few that would be of use with an irregular, round-ish shape (RBC). The stained parasite is rather blobby as well. No rotation or flips would be even noticable. The only possible assistance could come from trying different brightness or channel_shifts. (I did try them, but I got black images, so I used shear for the example images above).

###<b>Building the Model
"""

model_3=Sequential()

# Add hidden layers
model_3.add(Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation = 'relu', data_format='channels_last',input_shape = (224, 224, 3)))
model_3.add(Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation = 'relu',data_format='channels_last'))
model_3.add(MaxPool2D(pool_size=(2, 2)))
model_3.add(BatchNormalization())
model_3.add(Flatten())
model_3.add(Dense(64, activation = 'relu'))
model_3.add(Dropout(0.25))
model_3.add(BatchNormalization())
model_3.add(Dense(16, activation = 'relu'))
model_3.add(Dropout(0.25))

# Output layer
model_3.add(Dense(2, activation = 'sigmoid'))

"""<b>Using Callbacks"""

callback = EarlyStopping(monitor='loss', patience = 3)

"""<b> Fit and Train the model"""

# compile the model
model_3.compile(optimizer=Adam(learning_rate = 0.001), loss= 'categorical_crossentropy', metrics = ['accuracy'])

model_3.summary()

history_3 = model_3.fit(X_train_padded_norm, y_train_ohe, validation_split = 0.2, batch_size = 128, epochs = 20, verbose = 1, callbacks=callback)

"""###<B>Evaluating the model

<b>Plot the train and validation accuracy
"""

plt.figure(figsize=(8,8))
plt.plot(history_3.history['accuracy'])
plt.plot(history_3.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.ylim(0, 1)
plt.legend(['Train', 'Validation'], loc = 'upper left')
plt.show()

"""<B>Plotting the classification report and confusion matrix"""

y_pred_test=model_3.predict(X_test_padded_norm)

# reverse the one hot coding & calculate max probability
y_pred_classes = np.argmax(y_pred_test, axis = 1)
y_pred_max_prob = np.max(y_pred_test, axis = 1)

# Confirming the extra dimension added by the OHE has been removed
print(type(y_pred_classes[0]))
print(type(y_pred_max_prob[0]))
print(type(y_test_num[0]))


# print classification report
print(classification_report(y_test_num, y_pred_classes))

# Confusion matrix
cm=confusion_matrix(y_test_num, y_pred_classes)
y_classes = range(0,2)
plt.figure(figsize=(5,3))
sns.heatmap(cm, annot = True, fmt = '.0f', xticklabels = y_classes, yticklabels=y_classes)
plt.ylabel('Actual')
plt.xlabel('Predicted');

"""<b> Now, let us try to use a pretrained model like VGG16 and check how it performs on our data.

### **Pre-trained model (VGG16)**
- Import VGG16 network upto any layer you choose
- Add Fully Connected Layers on top of it
"""

backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)
random.seed(42)

from tensorflow.keras.applications.vgg16 import VGG16

model = VGG16(weights = 'imagenet')
model.summary

transfer_layer = model.get_layer('block5_pool')
vgg_model=VGG16(weights='imagenet', include_top = False, input_shape = (224, 224, 3))

# freeze VGG16 layers
for layer in vgg_model.layers:
  layer.trainable = False

for layer in vgg_model.layers:
  print(layer, layer.trainable)

model_4 = Sequential()
model_4.add(vgg_model)
model_4.add(Flatten())
model_4.add(Dense(64, activation = 'relu'))
model_4.add(Flatten())
model_4.add(Dense(32, activation = 'relu'))
model_4.add(Dropout(0.2))
model_4.add(Dense(16, activation = 'relu'))

# Output layer
model_4.add(Dense(2, activation = 'sigmoid'))

"""###<b>Compiling the model"""

# compile the model
model_4.compile(optimizer=Adam(learning_rate = 0.001), loss= 'categorical_crossentropy', metrics = ['accuracy'])

model_4.summary()

"""<b> using callbacks"""

callback = EarlyStopping(monitor='loss', patience = 3)

"""<b>Fit and Train the model"""

history_4 = model_4.fit(X_train_padded_norm, y_train_ohe, validation_split = 0.2, batch_size = 128, epochs = 20, verbose = 1, callbacks=callback)

"""<b>Plot the train and validation accuracy"""

plt.figure(figsize=(8,8))
plt.plot(history_4.history['accuracy'])
plt.plot(history_4.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.ylim(0, 1)
plt.legend(['Train', 'Validation'], loc = 'upper left')
plt.show()

"""###**Observations and insights: _____**

*   What can be observed from the validation and train curves?

###<b> Evaluating the model
"""

y_pred_test=model_4.predict(X_test_padded_norm)

"""<b>Plotting the classification report and confusion matrix"""

# reverse the one hot coding & calculate max probability
y_pred_classes = np.argmax(y_pred_test, axis = 1)
y_pred_max_prob = np.max(y_pred_test, axis = 1)

# Confirming the extra dimension added by the OHE has been removed
print(type(y_pred_classes[0]))
print(type(y_pred_max_prob[0]))
print(type(y_test_num[0]))


# print classification report
print(classification_report(y_test_num, y_pred_classes))

# Confusion matrix
cm=confusion_matrix(y_test_num, y_pred_classes)
y_classes = range(0,2)
plt.figure(figsize=(5,3))
sns.heatmap(cm, annot = True, fmt = '.0f', xticklabels = y_classes, yticklabels=y_classes)
plt.ylabel('Actual')
plt.xlabel('Predicted');

"""###<b>Think about it:</b>
*  What observations and insights can be drawn from the confusion matrix and classification report?
*  Choose the model with the best accuracy scores from all the above models and save it as a final model.

####<b> Observations and Conclusions drawn from the final model: _____

**Improvements that can be done:**<br>


*  Can the model performance be improved using other pre-trained models or different CNN architecture?
*  You can try to build a model using these HSV images and compare them with your other models.

#### **Insights**

####**Refined insights**:
- What are the most meaningful insights from the data relevant to the problem?

####**Comparison of various techniques and their relative performance**:
- How do different techniques perform? Which one is performing relatively better? Is there scope to improve the performance further?

####**Proposal for the final solution design**:
- What model do you propose to be adopted? Why is this the best solution to adopt?
"""
